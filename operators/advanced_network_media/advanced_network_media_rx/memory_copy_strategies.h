/*
 * SPDX-FileCopyrightText: Copyright (c) 2025-2026, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 * SPDX-License-Identifier: Apache-2.0
 */

#ifndef OPERATORS_ADVANCED_NETWORK_MEDIA_RX_MEMORY_COPY_STRATEGIES_H_
#define OPERATORS_ADVANCED_NETWORK_MEDIA_RX_MEMORY_COPY_STRATEGIES_H_

#include <memory>
#include <optional>
#include <utility>
#include <vector>
#include <cuda_runtime.h>
#include "frame_assembly_controller.h"
#include "../common/adv_network_media_common.h"

namespace holoscan::ops {

namespace detail {

/**
 * @brief Strategy types for copy operations
 */
enum class CopyStrategy {
  UNKNOWN,     // Memory copy strategy not yet determined
  CONTIGUOUS,  // Sequential memory copy strategy
  STRIDED      // Strided memory copy for HDS scenarios
};

/**
 * @brief Strategy interface for memory copy operations
 *
 * This interface defines how different memory copy strategies handle packet data.
 * While it coordinates with FrameAssemblyController, it belongs in the memory copy
 * domain because its primary responsibility is memory transfer optimization.
 */
class IMemoryCopyStrategy {
 public:
  virtual ~IMemoryCopyStrategy() = default;

  /**
   * @brief Process packet with assembly controller coordination
   * @param assembly_controller Reference to frame assembly controller
   * @param payload Packet payload data
   * @param payload_size Size of payload
   * @return Event generated by processing
   */
  virtual StateEvent process_packet(FrameAssemblyController& assembly_controller, uint8_t* payload,
                                    size_t payload_size) = 0;

  /**
   * @brief Execute accumulated copy operations
   * @param assembly_controller Reference to frame assembly controller for context updates
   * @return Event indicating copy result
   */
  virtual StateEvent execute_accumulated_copy(FrameAssemblyController& assembly_controller) = 0;

  /**
   * @brief Check if strategy has accumulated data waiting to be copied
   * @return True if accumulated data needs to be copied
   */
  virtual bool has_accumulated_data() const = 0;

  /**
   * @brief Get strategy type for debugging/statistics
   * @return Strategy type identifier
   */
  virtual CopyStrategy get_type() const = 0;

  /**
   * @brief Reset strategy state
   */
  virtual void reset() = 0;
};

/**
 * @brief Strategy detection and creation factory
 */
class StrategyFactory {
 public:
  /**
   * @brief Create strategy detector for pattern analysis
   * @return Strategy detector instance
   */
  static std::unique_ptr<class MemoryCopyStrategyDetector> create_detector();

  /**
   * @brief Create contiguous strategy
   * @param src_storage_type Source memory type
   * @param dst_storage_type Destination memory type
   * @return Contiguous strategy instance
   */
  static std::unique_ptr<IMemoryCopyStrategy> create_contiguous_strategy(
      nvidia::gxf::MemoryStorageType src_storage_type,
      nvidia::gxf::MemoryStorageType dst_storage_type);

  /**
   * @brief Create strided strategy
   * @param stride_info Detected stride information
   * @param src_storage_type Source memory type
   * @param dst_storage_type Destination memory type
   * @return Strided strategy instance
   */
  static std::unique_ptr<IMemoryCopyStrategy> create_strided_strategy(
      const StrideInfo& stride_info, nvidia::gxf::MemoryStorageType src_storage_type,
      nvidia::gxf::MemoryStorageType dst_storage_type);
};

/**
 * @brief Strategy detector for analyzing packet patterns
 */
class MemoryCopyStrategyDetector {
 public:
  static constexpr size_t DETECTION_PACKET_COUNT = 4;

  /**
   * @brief Configure detector with burst parameters
   * @param header_stride_size Header stride from burst info
   * @param payload_stride_size Payload stride from burst info
   * @param hds_enabled Whether header data split is enabled
   */
  void configure_burst_parameters(size_t header_stride_size, size_t payload_stride_size,
                                  bool hds_enabled);

  /**
   * @brief Collect packet for analysis
   * @param rtp_params RTP packet parameters
   * @param payload Payload pointer
   * @param payload_size Payload size
   * @return True if enough packets collected for detection
   */
  bool collect_packet(const RtpParams& rtp_params, uint8_t* payload, size_t payload_size);

  /**
   * @brief Analyze collected packets and determine strategy
   * @param src_storage_type Source memory storage type
   * @param dst_storage_type Destination memory storage type
   * @return Detected strategy or nullptr if detection failed
   */
  std::unique_ptr<IMemoryCopyStrategy> detect_strategy(
      nvidia::gxf::MemoryStorageType src_storage_type,
      nvidia::gxf::MemoryStorageType dst_storage_type);

  /**
   * @brief Check if detection is complete
   * @return True if strategy has been determined
   */
  bool is_detection_complete() const { return detection_complete_; }

  /**
   * @brief Reset detector for new detection cycle
   */
  void reset();

  /**
   * @brief Get number of packets analyzed
   * @return Packet count
   */
  size_t get_packets_analyzed() const { return packets_analyzed_; }

 private:
  /**
   * @brief Analyze collected packet pattern
   * @return Analysis result with strategy type and stride info
   */
  std::optional<std::pair<CopyStrategy, StrideInfo>> analyze_pattern();

  /**
   * @brief Validate RTP sequence continuity
   * @return True if no sequence drops detected
   */
  bool validate_sequence_continuity() const;

  /**
   * @brief Check for cyclic buffer wraparound
   * @return True if wraparound detected
   */
  bool detect_buffer_wraparound() const;

 private:
  // Detection data
  std::vector<uint8_t*> collected_payloads_;
  std::vector<size_t> collected_payload_sizes_;
  std::vector<uint64_t> collected_sequences_;
  size_t packets_analyzed_ = 0;
  bool detection_complete_ = false;

  // Burst configuration
  size_t expected_header_stride_ = 0;
  size_t expected_payload_stride_ = 0;
  bool hds_enabled_ = false;
};

/**
 * @brief Assembly controller aware contiguous strategy
 */
class ContiguousMemoryCopyStrategy : public IMemoryCopyStrategy {
 public:
  /**
   * @brief Constructor
   * @param src_storage_type Source memory storage type
   * @param dst_storage_type Destination memory storage type
   */
  ContiguousMemoryCopyStrategy(nvidia::gxf::MemoryStorageType src_storage_type,
                               nvidia::gxf::MemoryStorageType dst_storage_type);

  // IMemoryCopyStrategy interface
  StateEvent process_packet(FrameAssemblyController& assembly_controller, uint8_t* payload,
                            size_t payload_size) override;

  StateEvent execute_accumulated_copy(FrameAssemblyController& assembly_controller) override;

  bool has_accumulated_data() const override;
  void reset() override;
  CopyStrategy get_type() const override { return CopyStrategy::CONTIGUOUS; }

 private:
  /**
   * @brief Execute accumulated copy operation
   * @param assembly_controller Frame assembly controller reference
   * @return State event result
   */
  StateEvent execute_copy(FrameAssemblyController& assembly_controller);

  /**
   * @brief Validate copy operation bounds
   * @param assembly_controller Frame assembly controller reference
   * @return True if copy is safe to execute
   */
  bool validate_copy_bounds(FrameAssemblyController& assembly_controller) const;

 private:
  uint8_t* accumulated_start_ptr_ = nullptr;
  size_t accumulated_size_ = 0;
  cudaMemcpyKind copy_kind_;
  nvidia::gxf::MemoryStorageType src_storage_type_;
  nvidia::gxf::MemoryStorageType dst_storage_type_;
};

/**
 * @brief Assembly controller aware strided strategy
 */
class StridedMemoryCopyStrategy : public IMemoryCopyStrategy {
 public:
  /**
   * @brief Constructor
   * @param stride_info Stride pattern information
   * @param src_storage_type Source memory storage type
   * @param dst_storage_type Destination memory storage type
   */
  StridedMemoryCopyStrategy(const StrideInfo& stride_info,
                            nvidia::gxf::MemoryStorageType src_storage_type,
                            nvidia::gxf::MemoryStorageType dst_storage_type);

  // IMemoryCopyStrategy interface
  StateEvent process_packet(FrameAssemblyController& assembly_controller, uint8_t* payload,
                            size_t payload_size) override;

  StateEvent execute_accumulated_copy(FrameAssemblyController& assembly_controller) override;

  bool has_accumulated_data() const override;
  void reset() override;
  CopyStrategy get_type() const override { return CopyStrategy::STRIDED; }

 private:
  /**
   * @brief Check if stride pattern is maintained
   * @param payload Current packet payload pointer
   * @param payload_size Current packet payload size
   * @return True if stride is consistent
   */
  bool is_stride_maintained(uint8_t* payload, size_t payload_size);

  /**
   * @brief Execute strided copy operation
   * @param assembly_controller Frame assembly controller reference
   * @return State event result
   */
  StateEvent execute_strided_copy(FrameAssemblyController& assembly_controller);

  /**
   * @brief Execute individual packet copy (fallback)
   * @param assembly_controller Frame assembly controller reference
   * @param payload Packet payload
   * @param payload_size Payload size
   * @return State event result
   */
  StateEvent execute_individual_copy(FrameAssemblyController& assembly_controller, uint8_t* payload,
                                     size_t payload_size);

  /**
   * @brief Validate strided copy bounds
   * @param assembly_controller Frame assembly controller reference
   * @return True if copy is safe to execute
   */
  bool validate_strided_copy_bounds(FrameAssemblyController& assembly_controller) const;

  /**
   * @brief Reset accumulation state for new pattern
   * @param payload New packet payload
   * @param payload_size New packet size
   */
  void reset_accumulation(uint8_t* payload, size_t payload_size);

 private:
  StrideInfo stride_info_;

  // Accumulation state
  uint8_t* first_packet_ptr_ = nullptr;
  uint8_t* last_packet_ptr_ = nullptr;
  size_t accumulated_packet_count_ = 0;
  size_t accumulated_data_size_ = 0;

  // Stride validation
  bool stride_validated_ = false;
  size_t actual_stride_ = 0;

  // Memory configuration
  cudaMemcpyKind copy_kind_;
  nvidia::gxf::MemoryStorageType src_storage_type_;
  nvidia::gxf::MemoryStorageType dst_storage_type_;

  // Wraparound detection threshold
  static constexpr size_t WRAPAROUND_THRESHOLD = 1024 * 1024;
};

/**
 * @brief Helper functions for memory copy operations
 */
class CopyOperationHelper {
 public:
  /**
   * @brief Determine appropriate copy kind
   * @param src_storage_type Source memory type
   * @param dst_storage_type Destination memory type
   * @return CUDA copy kind
   */
  static cudaMemcpyKind get_copy_kind(nvidia::gxf::MemoryStorageType src_storage_type,
                                      nvidia::gxf::MemoryStorageType dst_storage_type);

  /**
   * @brief Execute safe memory copy with error handling
   * @param dst Destination pointer
   * @param src Source pointer
   * @param size Copy size
   * @param kind Copy kind
   * @return True if copy succeeded
   */
  static bool safe_copy(void* dst, const void* src, size_t size, cudaMemcpyKind kind);

  /**
   * @brief Execute safe 2D memory copy with error handling
   * @param dst Destination pointer
   * @param dst_pitch Destination pitch
   * @param src Source pointer
   * @param src_pitch Source pitch
   * @param width Copy width
   * @param height Copy height
   * @param kind Copy kind
   * @return True if copy succeeded
   */
  static bool safe_copy_2d(void* dst, size_t dst_pitch, const void* src, size_t src_pitch,
                           size_t width, size_t height, cudaMemcpyKind kind);
};

}  // namespace detail
}  // namespace holoscan::ops

#endif  // OPERATORS_ADVANCED_NETWORK_MEDIA_RX_MEMORY_COPY_STRATEGIES_H_
