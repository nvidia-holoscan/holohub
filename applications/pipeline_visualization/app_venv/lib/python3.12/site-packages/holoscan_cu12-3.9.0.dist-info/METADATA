Metadata-Version: 2.1
Name: holoscan-cu12
Version: 3.9.0
Summary: The Holoscan SDK: building high-performance AI streaming applications
Home-page: https://github.com/nvidia-holoscan
Author: NVIDIA Corporation
License: Apache-2.0
Project-URL: Source, https://github.com/nvidia-holoscan/holoscan-sdk
Project-URL: Documentation, https://docs.nvidia.com/holoscan/sdk-user-guide/index.html
Project-URL: Issue Tracker, https://github.com/nvidia-holoscan/holoscan-sdk/issues
Keywords: AI,CUDA,medical,streaming,HPC,nvidia
Classifier: Development Status :: 5 - Production/Stable
Classifier: Environment :: Console
Classifier: Environment :: GPU :: NVIDIA CUDA :: 12
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: Intended Audience :: Healthcare Industry
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: POSIX :: Linux
Classifier: Programming Language :: C++
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: public/LICENSE.txt
License-File: public/cmake/modules/cpack/NOTICE.txt
License-File: public/cmake/modules/cpack/README.md
License-File: legal/NVIDIA-AI-PRODUCT-EULA.txt
Requires-Dist: pip >22.0.2
Requires-Dist: numpy <3.0,>=1.0.4
Requires-Dist: cloudpickle <4.0,>=3.0
Requires-Dist: pillow >=11.2
Requires-Dist: cupy-cuda12x <14.0,>=12.2
Requires-Dist: wheel-axle-runtime <1.0

# Holoscan SDK

The **Holoscan SDK CUDA 12 Python Wheel** is part of [NVIDIA Holoscan](https://developer.nvidia.com/holoscan-sdk), the AI sensor processing platform that combines hardware systems for low-latency sensor and network connectivity, optimized libraries for data processing and AI, and core microservices to run streaming, imaging, and other applications, from embedded to edge to cloud. It can be used to build streaming AI pipelines for a variety of domains, including Medical Devices, High Performance Computing at the Edge, Industrial Inspection and more.

## Getting Started

Visit the Holoscan User Guide to [get started](https://docs.nvidia.com/holoscan/sdk-user-guide/getting_started.html) with the Holoscan SDK.

## Prerequisites

- Prerequisites for each supported platform are documented in [the user guide](https://docs.nvidia.com/holoscan/sdk-user-guide/sdk_installation.html#prerequisites). Note that the python wheels have a lot of optional dependencies which you may install manually based on your needs (see compatibility matrix at the bottom).
- The `holoscan-cu12` python wheels are formally tested on Ubuntu 22.04. They are generally expected to work on any Linux distribution with glibc 2.35 or above (see output of `ldd --version`) and CUDA Runtime 12.6 or above.
- Python: 3.10 to 3.13

## Troubleshooting

> Version 0.6.0 gets installed instead of the latest version

The latest version of the wheels were built and tested on Ubuntu 22.04 with glibc 2.35. You'll need to switch to a Linux distribution with a more recent version of glibc to use the Holoscan SDK python wheels 1.0 or above (check your version with `ldd --version`), or use the [Holoscan SDK NGC container](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/clara-holoscan/containers/holoscan) instead.

> ```console
> ERROR: Could not find a version that satisfies the requirement holoscan-cu12==<version>
> ERROR: No matching distribution found for holoscan-cu12==<version>
> ```

> ```console
> ERROR: Could not find a version that satisfies the requirement holoscan-cu13==<version>
> ERROR: No matching distribution found for holoscan-cu13==<version>
> ```

Same as above, OR incompatible python version.

> ```console
> libc.so.6: version 'GLIBC_2.32 not found
> libstdc++.so.6: version `GLIBCXX_3.4.29` not found
> ```

Same as above.

> ```console
> ImportError: libcudart.so.12: cannot open shared object file: No such file or directory
> ```
>
> ```console
> ImportError: libcudart.so.13: cannot open shared object file: No such file or directory
> ```

CUDA runtime is missing from your system (required even for CPU only pipelines).

- **x86_64**: two options
  - A) System Installation: Follow the official [installation steps](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html) for installing the CUDA Toolkit.
  - B) PIP installation:
    - For `holoscan-cu12`:

      ```sh
      python3 -m pip install nvidia-cuda-runtime-cu12
      ```
      
    - Export the CUDA runtime library path:

      ```sh
      export CUDA_WHL_LIB_DIR=$(python3 -c 'import nvidia.cuda_runtime; print(nvidia.cuda_runtime.__path__[0])')/lib
      export LD_LIBRARY_PATH="$CUDA_WHL_LIB_DIR:$LD_LIBRARY_PATH"
      ```

- **IGX Orin**: Ensure the [compute stack](https://docs.nvidia.com/igx-orin/user-guide/latest/base-os.html#installing-the-compute-stack) is installed.
- **Jetson Orin**: Re-install [JetPack 6.2.1](https://developer.nvidia.com/embedded/jetpack).

> ```console
> catastrophic error: cannot open source file "vector_types.h"
> ```

CUDA Runtime headers are missing from your system.

Resolution: same as above.

Reference: <https://docs.cupy.dev/en/latest/install.html#cupy-always-raises-nvrtc-error-compilation-6>

> ```console
> Error: libnvinfer.so.8: cannot open shared object file: No such file or directory
> ...
> Error: libnvonnxparser.so.8: cannot open shared object file: No such file or directory
> ```

TensorRT is missing from your system (note that it is only needed by the `holoscan.operators.InferenceOp` operator.).

- **x86_64**:
  - A) System Installation: Follow the official [installation steps](https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html).
  - B) PIP installation:

    ```sh
    python3 -m pip install tensorrt-libs~=8.6.1 --index-url https://pypi.nvidia.com
    export TRT_WHL_LIB_DIR=$(python3 -c 'import tensorrt_libs; print(tensorrt_libs.__path__[0])')
    export CUDNN_WHL_LIB_DIR=$(python3 -c 'import nvidia.cudnn; print(nvidia.cudnn.__path__[0])')/lib
    export CUBLAS_WHL_LIB_DIR=$(python3 -c 'import nvidia.cublas; print(nvidia.cublas.__path__[0])')/lib
    export LD_LIBRARY_PATH="$TRT_WHL_LIB_DIR:$CUDNN_WHL_LIB_DIR:$CUBLAS_WHL_LIB_DIR:$LD_LIBRARY_PATH"
    ```

- **IGX Orin**: Ensure the [compute stack](https://docs.nvidia.com/igx-orin/user-guide/latest/base-os.html#installing-the-compute-stack) is installed.
- **Jetson**: Re-install [JetPack 6.2.1](https://developer.nvidia.com/embedded/jetpack).
