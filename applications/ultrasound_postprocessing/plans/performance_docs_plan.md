# Performance Evaluation Documentation Plan

**Created:** 2025-11-28  
**By:** Gemini-3-Pro-Preview

## Goal
Create documentation and tools to evaluate the latency performance of presets using the Holoscan SDK's `Tracker`.

## Steps

1.  **Create `docs/performance_evaluation.md`**
    -   Explain the purpose of performance evaluation.
    -   Describe how to run `ultra_post.app.holoscan_app` to generate logs.
    -   Explain the `Tracker` mechanism.
    -   Provide instructions on analyzing the logs to identify bottlenecks.

2.  **Create `tools/analyze_holoscan_log.py`**
    -   A Python script to parse the Holoscan log file.
    -   Calculate average latency per operator.
    -   Calculate end-to-end latency (source to sink).
    -   Display results in a table.
    -   *Note: This script will assume a standard text-based log format. If the log is binary/SQLite, we will adjust.*

3.  **Update `README.md`**
    -   Add a section linking to the new performance documentation.

4.  **Verify**
    -   (User to verify) Run the app and the analysis tool to ensure they work.

## Log Format Assumption
We assume the log file generated by `Tracker` contains lines with timestamps and operator names, or message events. If `Tracker` uses the newer Data Flow Tracking (DFT) which might be binary or specific, we will note this.
*Self-correction*: `Tracker` in Holoscan v0.6+ often writes to a file that might need specific parsing. We will start with a robust text parser or use `holoscan.core.Tracker` methods if available in a separate analysis script (though the analysis usually happens post-mortem).

## Deliverables
- `docs/performance_evaluation.md`
- `tools/analyze_holoscan_log.py`


