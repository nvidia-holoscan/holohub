Ultrasound Post-Processing (WIP)
================================

**Mission:** To enable the ultrasound community (academia and industry) to have reproducible, real-time post-processing.

**Overview:**
This project includes an Ultrasound Post-Processing Filter Designer and light-weight library that enables you to design and run your ultrasound post-processing filter collection in Holoscan, all from a small and simple YAML config file.

- The **Filter Designer** enables you to create the YAML configs working on UFF files (beamformed but not log compressed). You can load and filter your own data locally.
- The **Holoscan Runner** enables you to run those configurations in real-time using the [Holoscan SDK](https://github.com/nvidia-holoscan/holoscan-sdk).
- **Benchmarking** is supported to evaluate performance.

## Run the Streamlit Filter Designer

1. Install dependencies (uses the `pyproject.toml` list):

   ```bash
   uv sync
   ```

2. Launch the GPU Streamlit app:

   ```bash
   uv run streamlit run ultra_post/app/gui/streamlit_app.py
   ```

Place a demo UFF frame at `ultra_post/examples/demo.uff` (download from [Google Drive](https://drive.google.com/drive/folders/1aaWnWNI8gBiqok4QZT8PEbRZZtKMra-C?usp=drive_link)) or upload one through the UI. The current build loads the frame onto the GPU, applies the selected compression operator (power/log, partial log, or gamma), and renders original vs. processed views. CUDA-capable hardware with the CuPy CUDA 12.x build is required.

## HoloScan Runtime

Install the optional extra (Linux):

```bash

# Or install all developer extras (convenience meta-extra)
uv pip install .[all]
```

Run the minimal HoloScan app (headless fallback if HoloScan is unavailable):

```bash
uv run python -m ultra_post.app.holoscan_app --source uff --uff ultra_post/examples/demo.uff --fps 30
```

### Use the i4h-sensor-simulation raysim backend

You can drive the same HoloScan pipeline with synthetic B-mode frames generated by the
[i4h-sensor-simulation](https://github.com/isaac-for-healthcare/i4h-sensor-simulation) repo:

1. Clone and install the simulator (OptiX/CUDA toolchain required):
   ```bash
   git clone https://github.com/isaac-for-healthcare/i4h-sensor-simulation external/i4h-sensor-simulation
   uv pip install -e external/i4h-sensor-simulation/ultrasound-raytracing
   ```
2. Launch the HoloScan app in raysim mode:
   ```bash
   uv run python -m ultra_post.app.holoscan_app \
     --source raysim \
     --sim-frames 90 \
     --sim-range -30 30 \
     --sim-size 512 512 \
     --fps 30
   ```

The raysim bridge sweeps a curvilinear probe over the included two-sphere phantom, normalizes the
simulated output to `[0, 1]`, and feeds it directly into the filter pipeline and Holoviz display.
All `--sim-*` flags are optional tweaks for probe geometry, resolution, and dynamic range.

## Performance Evaluation

To benchmark presets and identify bottlenecks using the Holoscan SDK:

1. Run the app with `--log performance.log`.
2. Use the provided tool to analyze latency:
   ```bash
   uv run python tools/analyze_holoscan_log.py performance.log
   ```

See [Performance Evaluation](docs/performance_evaluation.md) for details.

### Benchmark Results

The following benchmark was run on a **NVIDIA RTX PRO 6000 Blackwell Max-Q Workstation Edition** using the `presets/benchmark.yml` preset which includes all available operators in a single pipeline.

**End-to-End Latency:** ~79.7ms (~12.5 FPS) (excluding first/last 10 frames)

| Operator | Avg (ms) | Count |
| :--- | :--- | :--- |
| frame_source | 0.052 | 1116 |
| gamma_compression_0 | 0.144 | 1116 |
| clahe_1 | 10.504 | 1116 |
| adaptive_gray_map_2 | 0.831 | 1116 |
| median_filter_3 | 0.327 | 1116 |
| gaussian_filter_4 | 0.220 | 1116 |
| unsharp_mask_5 | 0.238 | 1116 |
| anisotropic_diffusion_6 | 3.555 | 1116 |
| bilateral_filter_7 | 3.628 | 1116 |
| guided_filter_8 | 0.683 | 1116 |
| non_local_means_9 | 15.233 | 1116 |
| svd_denoise_10 | 39.576 | 1116 |
| persistence_11 | 0.128 | 1116 |
| temporal_svd_12 | 2.837 | 1116 |
| color_map_13 | 0.347 | 1116 |
| to_rgba | 0.170 | 1116 |
| holoviz | 0.125 | 1116 |

*Note: Most pipelines will only use a subset of these operators, resulting in significantly higher FPS. The first and last 10 samples were discarded to remove startup/shutdown jitter.*

**Investigation Note:** The high maximum latency values are driven by rare periodic spikes (occurring <1% of the time). Preliminary analysis suggests this may be related to Holoscan resource contention or system-level memory management rather than the operators themselves. An internal issue should be opened to investigate these spikes further.



## CLI helpers

- `uv run uspp list-ops` to see discovered operators and defaults.
- `uv run uspp validate-preset presets/preset.yml` to sanity check a YAML preset.

## Authoring guide

### Add a new operator
1. **Create the file**: Add `ultra_post/ops/my_filter.py`:
   ```python
   import cupy as cp

   def my_filter(image: cp.ndarray, strength: float = 0.5) -> cp.ndarray:
       """Docstring becomes the UI tooltip."""
       return image * strength
   ```
2. **Register it**: Edit `ultra_post/ops/registry.py`:
   ```python
   # ... existing imports
   from . import my_filter  # <--- 1. Import it

   OPS = {
       # ...
       "my_filter": my_filter.my_filter,  # <--- 2. Map name to function
   }

   DEFAULT_PARAMS = {
       # ...
       "my_filter": {"strength": 0.5},  # <--- 3. Define UI defaults
   }
   ```

### Create a preset
1. Build a pipeline in the Streamlit UI, then click **Save Preset** to download YAML.
2. Place presets under `presets/` (version `1`, snake_case op names).
3. Validate with `uv run uspp validate-preset presets/your_preset.yml` (also covered by tests).

### Streamlit / HoloScan usage
- Streamlit: `uv run streamlit run ultra_post/app/gui/streamlit_app.py` (upload UFF or load a preset).
- HoloScan: `uv run python -m ultra_post.app.holoscan_app --source uff --uff ultra_post/examples/demo.uff --fps 30` (uses the same presets/operators; Holoviz FPS enabled).
