## Endoscopy Tool Tracking Application

Digital endoscopy is a key technology for medical screenings and minimally invasive surgeries. Using real-time AI workflows to process and analyze the video signal produced by the endoscopic camera, this technology helps medical professionals with anomaly detection and measurements, image enhancements, alerts, and analytics.


![](docs/app_endoscopy.png)<br>
Fig. 1 Endoscopy (laparoscopy) image from a cholecystectomy (gallbladder removal surgery) showing AI-powered frame-by-frame tool identification and tracking. Image courtesy of Research Group Camma, IHU Strasbourg and the University of Strasbourg ([NGC Resource](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/clara-holoscan/resources/holoscan_endoscopy_sample_data))



The Endoscopy tool tracking application provides an example of how an endoscopy data stream can be captured and processed using the C++ or Python APIs on multiple hardware platforms.

### Video Stream Replayer Input
![](docs/workflow_tool_tracking_replayer.png)<br>
Fig. 2 Tool tracking application workflow with replay from file


The pipeline uses a recorded endoscopy video file (generated by `convert_video_to_gxf_entities` script) for input frames. Each input frame in the file is loaded by [Video Stream Replayer](https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_operators_extensions.html#operators) and passed to the following two branches:
- In the first branch, the input frames are directly passed to [Holoviz](https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_operators_extensions.html#operators) for rendering in the background.
- In the second branch, the frames go through the [Format Converter](https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_operators_extensions.html#operators) to convert the data type of the image from `uint8` to `float32` before it is fed to the tool tracking model (with [Custom TensorRT Inference](https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_operators_extensions.html#operators)). The result is then ingested by the [Tool Tracking Postprocessor](https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_operators_extensions.html#operators) which extracts the masks, points, and text from the inference output, before [Holoviz](https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_operators_extensions.html#operators) renders them as overlays.

The pipeline graph also defines an optional [Video Stream Recorder](https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_operators_extensions.html#stream-playback) that can be enabled to record the original video stream to disk (`record_type: 'input'`), or the final render by Holoviz (`record_type: 'visualizer'`) after going from `RGBA8888` to `RGB888` using a [Format Converter](https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_operators_extensions.html#operators). Recording is disabled by default (`record_type: 'none'`) in order to maximize performance.


### AJA Card input

![](docs/workflow_tool_tracking_aja.png)<br>
Fig. 3 Tool tracking application workflow with input from AJA video source

The pipeline is similar to the one using the recorded video, with the exceptions below:
- the input source is replaced with [AJA Source](https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_operators_extensions.html#operators) (pixel format is `RGBA8888` with a resolution of 1920x1080)
- the [Format Converter](https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_operators_extensions.html#operators) in the inference pipeline is configured to also resize the image, and convert to `float32` from `RGBA8888`
- the [Format Converter](https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_operators_extensions.html#operators) in the recording pipeline is used for `record_type: INPUT` also

For AJA cards that support Hardware Keying, the pipeline can also be configured to overlay the segmentation results on the input video on the AJA card FPGA, instead of on the GPU: when `is_aja_overlay_enabled` is True, the overlay layer is sent from [Holoviz](https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_operators_extensions.html#operators) back to the [AJA Source](https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_operators_extensions.html#operators) operator which handles the alpha blending and outputs it to a port of the the AJA card. The blended image is also sent back to the [Holoviz](https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_operators_extensions.html#operators) operator (instead of the input video only) for rendering the same image buffer.
*The overlay configuration does not work with Holoscan SDK v0.6. As Holoscan supports only [Directed
Acyclic Graph (DAG) for a
fragment](https://docs.nvidia.com/holoscan/sdk-user-guide/holoscan_core.html), the cycle formed by
the edge between the Holoviz and AJA Source operators is incompatible. The overlay feature will
again be available in a future release of Holoscan SDK.*

### Using VTK for rendering

The tool tracking application can use the [VTK](https://vtk.org/) library to
render the tool tracking results on top of the endoscopy video frames. The VTK
library is a powerful open-source software system for 3D computer graphics,
image processing, and visualization. The VTK library provides a wide range of
functionalities for rendering, including 2D and 3D graphics, image processing,
and visualization. The tool tracking application uses VTK to render the tool
tracking results on top of the endoscopy video frames.


### How to build the tool tracking application with VTK

Build the HoloHub container as described at the root [README.md](../../README.md)

You need to create a docker image which includes VTK with the provided
`vtk.Dockerfile` in the `operator/vtk_renderer` subdirectory:

```bash
docker build -t vtk:latest -f vtk.Dockerfile .
```
Set vtk as the visualizer by:

* Using a vtk_renderer instead of holoviz
    ```bash
    sed -i -e 's#^visualizer:.*#visualizer: "vtk"#' applications/endoscopy_tool_tracking/cpp/endoscopy_tool_tracking.yaml
    applications/endoscopy_tool_tracking/cpp/endoscopy_tool_tracking --data <data_dir>/endoscopy
    ```
Then, you can build the tool tracking application with the provided
`Dockerfile`:

```bash
./dev_container launch --img vtk:latest
```

Inside the container you can build the application with:

```bash
./run build endoscopy_tool_tracking --with vtk_renderer
```

Now you can run the tool tracking application with:

```bash
./run launch endoscopy_tool_tracking cpp
```
